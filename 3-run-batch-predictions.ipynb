{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run batch predictions using SageMaker Autopilot trained best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from time import gmtime, strftime\n",
    "from sagemaker import AutoML\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('__name__')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using SageMaker version: 2.70.0\n",
      "Using Boto3 version: 1.20.23\n",
      "Using Pandas version: 1.0.1\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Using SageMaker version: {sagemaker.__version__}')\n",
    "logger.info(f'Using Boto3 version: {boto3.__version__}')\n",
    "logger.info(f'Using Pandas version: {pd.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign S3 location to park our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = 'customer-churn-prediction'\n",
    "region = 'us-east-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set your batch input and output S3 locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch input S3 location: s3://sagemaker-us-east-1-119174016168/customer-churn-prediction/batch_input/\n"
     ]
    }
   ],
   "source": [
    "batch_input = f's3://{bucket}/{prefix}/batch_input/'\n",
    "logger.info(f'Batch input S3 location: {batch_input}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch output S3 location: s3://sagemaker-us-east-1-119174016168/customer-churn-prediction/batch_output/\n"
     ]
    }
   ],
   "source": [
    "batch_output = f's3://{bucket}/{prefix}/batch_output/'\n",
    "logger.info(f'Batch output S3 location: {batch_output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create clients and resources "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session()\n",
    "region = session.region_name\n",
    "sagemaker_client = session.client('sagemaker', region_name=region)\n",
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interact with your previously run Autopilot Experiment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create automl instance using previously created Autopilot experiment name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autopilot_experiment_name = '<ENTER YOUR AUTOPILOT EXPERIMENT NAME HERE>'\n",
    "autopilot_experiment_name = 'churn-prediction-experiment'\n",
    "automl = AutoML.attach(auto_ml_job_name=autopilot_experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define inference response keys\n",
    "\n",
    "\n",
    "Valid inference response keys can be set based on the problem type - binary classification or multiclass classification.\n",
    "\n",
    "* `predicted_label` - Predicted class \n",
    "\n",
    "* `probability` - In binary classification, the probability that the result is predicted as the second or True class in the target column. In multiclass classification, the probability of the winning class.\n",
    "    \n",
    "* `labels` - List of all possible classes \n",
    "\n",
    "* `probabilities` - List of all probabilities for all classes (order corresponds with 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_response_keys = ['predicted_label', 'probability']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get best candidate model details using the automl created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best candidate name: churn-prediction-experimentGqPsk-126-3e37f694\n"
     ]
    }
   ],
   "source": [
    "best_candidate = automl.describe_auto_ml_job()['BestCandidate']\n",
    "best_candidate_name = best_candidate['CandidateName']\n",
    "logger.info(f'Best candidate name: {best_candidate_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective metric name: validation:binary_f_beta\n",
      "Objective metric value: 0.9682851433753967\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Objective metric name: {best_candidate['FinalAutoMLJobObjectiveMetric']['MetricName']}\")\n",
    "logger.info(f\"Objective metric value: {best_candidate['FinalAutoMLJobObjectiveMetric']['Value']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recreate the best model using the identified candidate name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = automl.create_model(name=best_candidate_name, \n",
    "                            candidate=best_candidate, \n",
    "                            inference_response_keys=inference_response_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make batch predictions using the Autopilot model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a transformer using the above re-created model to run batch predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: churn-prediction-experimentGqPsk-126-3e37f694\n"
     ]
    }
   ],
   "source": [
    "transformer = model.transformer(instance_count=1, \n",
    "                                instance_type='ml.m5.xlarge', \n",
    "                                assemble_with='Line', \n",
    "                                output_path=batch_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kick-off the batch predictions job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.transform(data=batch_input, \n",
    "                      split_type='Line', \n",
    "                      content_type='text/csv', \n",
    "                      wait=False)\n",
    "transformer_current_job_name = transformer._current_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running batch predictions job using SageMaker Batch Transform: churn-prediction-experimentGqPsk-126-3e-2022-02-23-17-53-25-199\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Running batch predictions job using SageMaker Batch Transform: {transformer_current_job_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the status of the running job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Job status: InProgress\n",
      "Job status: InProgress\n",
      "Job status: InProgress\n",
      "Job status: InProgress\n",
      "Job status: InProgress\n",
      "Job status: InProgress\n",
      "Job status: InProgress\n",
      "Job status: InProgress\n",
      "Job status: InProgress\n",
      "Job status: InProgress\n",
      "Job status: InProgress\n",
      "Job status: InProgress\n",
      "Job status: InProgress\n",
      "Job status: InProgress\n",
      "Job status: Completed\n"
     ]
    }
   ],
   "source": [
    "response = sagemaker_client.describe_transform_job(TransformJobName=transformer_current_job_name)\n",
    "status = response['TransformJobStatus']\n",
    "logger.info(f'Job status: {status}')\n",
    "\n",
    "while status not in ('Failed', 'Completed', 'Stopped'):\n",
    "    response = sagemaker_client.describe_transform_job(TransformJobName=transformer_current_job_name)\n",
    "    status = response['TransformJobStatus']\n",
    "    logger.info(f'Job status: {status}')\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the results of the batch job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_key = f'{prefix}/batch_output/unlabeled.csv.out'\n",
    "local_file_save_path = './results.csv'\n",
    "results_bucket = s3.Bucket(bucket)\n",
    "results_bucket.download_file(s3_output_key, local_file_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>predicted_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False.</td>\n",
       "      <td>0.000174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False.</td>\n",
       "      <td>0.001264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True.</td>\n",
       "      <td>0.997513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False.</td>\n",
       "      <td>0.000998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True.</td>\n",
       "      <td>0.999312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>True.</td>\n",
       "      <td>0.999278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>True.</td>\n",
       "      <td>0.997822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>False.</td>\n",
       "      <td>0.000278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>True.</td>\n",
       "      <td>0.914709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>True.</td>\n",
       "      <td>0.998485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    predicted_label  predicted_probability\n",
       "0            False.               0.000174\n",
       "1            False.               0.001264\n",
       "2             True.               0.997513\n",
       "3            False.               0.000998\n",
       "4             True.               0.999312\n",
       "..              ...                    ...\n",
       "495           True.               0.999278\n",
       "496           True.               0.997822\n",
       "497          False.               0.000278\n",
       "498           True.               0.914709\n",
       "499           True.               0.998485\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.read_csv(local_file_save_path, sep=',', names=['predicted_label', 'predicted_probability']) \n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
