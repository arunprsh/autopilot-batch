{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run batch predictions using SageMaker Autopilot trained best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from time import gmtime, strftime\n",
    "from sagemaker import AutoML\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "import logging\n",
    "import boto3\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('__name__')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using SageMaker version: 2.70.0\n",
      "Using Boto3 version: 1.20.23\n",
      "Using Pandas version: 1.0.1\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Using SageMaker version: {sagemaker.__version__}')\n",
    "logger.info(f'Using Boto3 version: {boto3.__version__}')\n",
    "logger.info(f'Using Pandas version: {pd.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign S3 location to park our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = 'customer-churn-prediction'\n",
    "region = 'us-east-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set your batch input and output S3 locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch input S3 location: s3://sagemaker-us-east-1-119174016168/customer-churn-prediction/batch_input/\n"
     ]
    }
   ],
   "source": [
    "batch_input = f's3://{bucket}/{prefix}/batch_input/'\n",
    "logger.info(f'Batch input S3 location: {batch_input}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch output S3 location: s3://sagemaker-us-east-1-119174016168/customer-churn-prediction/batch_output/\n"
     ]
    }
   ],
   "source": [
    "batch_output = f's3://{bucket}/{prefix}/batch_output/'\n",
    "logger.info(f'Batch output S3 location: {batch_output}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.Session()\n",
    "sagemaker_client = boto3.client('sagemaker', region_name=region)\n",
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interact with your previously run Autopilot Experiment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create automl instance using previously created Autopilot experiment name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autopilot_experiment_name = '<ENTER YOUR AUTOPILOT EXPERIMENT NAME HERE>'\n",
    "autopilot_experiment_name = 'churn-prediction-experiment'\n",
    "automl = AutoML.attach(auto_ml_job_name=autopilot_experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define inference response keys\n",
    "\n",
    "\n",
    "Valid inference response keys can be set based on the problem type - binary classification or multiclass classification.\n",
    "\n",
    "* `predicted_label` - Predicted class \n",
    "\n",
    "* `probability` - In binary classification, the probability that the result is predicted as the second or True class in the target column. In multiclass classification, the probability of the winning class.\n",
    "    \n",
    "* `labels` - List of all possible classes \n",
    "\n",
    "* `probabilities` - List of all probabilities for all classes (order corresponds with 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_response_keys = ['predicted_label', 'probability']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get best candidate model details using the automl created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best candidate name: churn-prediction-experimentGqPsk-126-3e37f694\n"
     ]
    }
   ],
   "source": [
    "best_candidate = automl.describe_auto_ml_job()['BestCandidate']\n",
    "best_candidate_name = best_candidate['CandidateName']\n",
    "logger.info(f'Best candidate name: {best_candidate_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective metric name: validation:binary_f_beta\n",
      "Objective metric value: 0.9682851433753967\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Objective metric name: {best_candidate['FinalAutoMLJobObjectiveMetric']['MetricName']}\")\n",
    "logger.info(f\"Objective metric value: {best_candidate['FinalAutoMLJobObjectiveMetric']['Value']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recreate the best model using the identified candidate name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = automl.create_model(name=best_candidate_name, \n",
    "                            candidate=best_candidate, \n",
    "                            inference_response_keys=inference_response_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make batch predictions using the Autopilot model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a transformer using the above re-created model to run batch predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: churn-prediction-experimentGqPsk-126-3e37f694\n"
     ]
    }
   ],
   "source": [
    "transformer = model.transformer(instance_count=1, \n",
    "                                instance_type='ml.m5.xlarge', \n",
    "                                assemble_with='Line', \n",
    "                                output_path=batch_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kick-off the batch predictions job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer.transform(data=batch_input, \n",
    "                      split_type='Line', \n",
    "                      content_type='text/csv', \n",
    "                      wait=False)\n",
    "transformer_current_job_name = transformer._current_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running batch predictions job using SageMaker Batch Transform: churn-prediction-experimentGqPsk-126-3e-2022-02-23-16-36-54-656\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Running batch predictions job using SageMaker Batch Transform: {transformer_current_job_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the status of the running job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sagemaker_client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-83af7f9ae823>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe_transform_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTransformJobName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransformer_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TransformJobStatus'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Job status: {status}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Failed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Completed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Stopped'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sagemaker_client' is not defined"
     ]
    }
   ],
   "source": [
    "response = sagemaker_client.describe_transform_job(TransformJobName=transformer_current_job_name)\n",
    "status = response['TransformJobStatus']\n",
    "logger.info(f'Job status: {status}')\n",
    "\n",
    "while status not in ('Failed', 'Completed', 'Stopped'):\n",
    "    response = sagemaker_client.describe_transform_job(TransformJobName=transformer_current_job_name)\n",
    "    status = response['TransformJobStatus']\n",
    "    logger.info(f'Job status: {status}')\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
